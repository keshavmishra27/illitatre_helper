<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multilingual Voice Agent</title>
    <style>
        /* Base Styles */
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; 
            padding: 0; 
            background-color: #0d1117; 
            color: #e6edf3; 
            padding-top: 60px; /* IMPORTANT: Add padding for fixed navbar */
        }
        .container { 
            max-width: 800px; margin: 20px auto; padding: 20px; background-color: #161b22; 
            border-radius: 12px; box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5); 
            position: relative; z-index: 10; 
        }
        h1, h2 { color: #58a6ff; text-align: center; margin-bottom: 20px; }
        hr { border-color: #30363d; margin: 30px 0; }

        /* --- NAVBAR STYLES --- */
        .navbar {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 60px;
            background-color: #1f2730; 
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
            display: flex; align-items: center; justify-content: space-between;
            padding: 0 20px; z-index: 100;
        }
        .navbar-brand {
            color: #58a6ff; font-size: 1.5em; font-weight: 600; text-decoration: none;
        }
        .navbar-links a {
            color: #e6edf3; text-decoration: none; padding: 10px 15px; border-radius: 5px;
            margin-left: 10px; transition: background-color 0.2s;
        }
        .navbar-links a:hover {
            background-color: #30363d;
        }
        /* --- END NAVBAR STYLES --- */

        /* Loading Screen Styles */
        #loading-screen {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%; background-color: #0d1117;
            display: flex; justify-content: center; align-items: center; flex-direction: column; z-index: 1000;
            transition: opacity 1s ease-out; opacity: 1;
        }
        #loading-text { color: #58a6ff; font-size: 1.5em; margin-top: 20px; }
        #loading-animation-container { width: 200px; height: 200px; }

        /* AI Visualizer Styles */
        #visualizer-container {
            width: 100%; height: 250px; background-color: #0d1117; border-radius: 8px; margin-bottom: 20px;
            overflow: hidden; display: flex; justify-content: center; align-items: center; border: 1px solid #30363d;
        }

        /* Controls Styles */
        #record-button, #stop-button {
            padding: 12px 25px; font-size: 1em; cursor: pointer; margin: 8px; border: none; border-radius: 25px;
            color: white; transition: background-color 0.3s ease, transform 0.1s ease; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.4);
        }
        #record-button { background-color: #28a745; }
        #stop-button { background-color: #dc3545; }
        
        #mic-status { color: #e6edf3; font-weight: bold; margin-top: 10px; }
        #mic-status.recording { color: #dc3545; }
        #mic-status.playing { color: #007bff; }
        #mic-status.processing { color: #ffc107; }

        /* Conversation Styles */
        #messages { max-height: 300px; overflow-y: auto; padding-right: 10px; }
        .message-user { text-align: right; margin-bottom: 10px; }
        .message-user span { background-color: #007bff; color: white; padding: 8px 12px; border-radius: 15px 15px 0 15px; display: inline-block; max-width: 70%; word-wrap: break-word; }
        .message-agent { text-align: left; margin-bottom: 10px; }
        .message-agent span { background-color: #28a745; color: white; padding: 8px 12px; border-radius: 15px 15px 15px 0; display: inline-block; max-width: 70%; word-wrap: break-word; }
    </style>
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>

<!-- NEW NAVBAR -->
<nav class="navbar">
    <a href="{{ url_for('main_blueprint.index') }}" class="navbar-brand">üó£Ô∏è Voice Agent</a>
    <div class="navbar-links">
        <!-- Assuming you created a route named 'main_blueprint.ocr_page' -->
        <a href="{{ url_for('main_blueprint.ocr_page') }}">üì∏ OCR Extractor</a>
        <a href="{{ url_for('main_blueprint.index') }}">üè† Home</a>
    </div>
</nav>
<!-- END NEW NAVBAR -->
    
<div id="loading-screen">
        <div id="loading-animation-container"></div>
        <p id="loading-text">Initializing Agent...</p>
    </div>

    
<div class="container" id="app-content" style="opacity: 0; transition: opacity 1s ease-in;">
        <h1>üó£Ô∏è Personalized Voice Agent</h1>
        
        <div id="visualizer-container"></div>

        <div id="status-panel">
            <h2>User Profile Status</h2>
            <p>This is where your agent stores the details it collects:</p>
            <ul>
                <li>**Name:** <span id="user-name">{{ user.name if user.name != 'N/A' else 'Missing' }}</span></li>
                <li>**Age:** <span id="user-age">{{ user.age if user.age != 0 else 'Missing' }}</span></li>
                <li>**Language:** <span id="user-lang">{{ user.language }}</span></li>
            </ul>
            <p id="agent-status-text">
                {% if user.name == 'N/A' %}
                    Agent is ready to collect your **Name**.
                {% elif user.age == 0 %}
                    Agent is ready to collect your **Age**.
                {% else %}
                    <span style="color: green;">Setup Complete. Agent is in normal chat mode.</span>
                {% endif %}
            </p>
        </div>

        <hr>
        
        <div id="controls">
            <button id="record-button">üéôÔ∏è Start Speaking</button>
            <button id="stop-button" disabled>üõë Stop & Send</button>
            <p id="mic-status">Microphone Status: Idle</p>
            <audio id="audio-player" hidden></audio>
        </div>

        <div id="conversation">
            <h2>Conversation Log</h2>
            <div id="messages">
                <div class="message-agent">
                    <span>
                        {% if user.language == 'en' %}
                            Hello! Please click "Start Speaking" to begin our conversation.
                        {% elif user.language == 'es' %}
                            ¬°Hola! Por favor, haz clic en "Empezar a hablar" para comenzar nuestra conversaci√≥n.
                        {% else %}
                            Hello! Please click "Start Speaking" to begin our conversation.
                        {% endif %}
                    </span>
                </div>
            </div>
        </div>
    </div>

    <script>
        // === JINJA2 INITIAL DATA ===
        const INITIAL_USER_DETAILS = {
            name: "{{ user.name }}",
            age: parseInt("{{ user.age }}"),
            language: "{{ user.language }}"
        };

        // === THREE.JS LOADING SCREEN ANIMATION ===
        const loadingScreen = document.getElementById('loading-screen');
        const loadingAnimationContainer = document.getElementById('loading-animation-container');
        const appContent = document.getElementById('app-content');
        
        let loadingScene, loadingCamera, loadingRenderer, loadingCube;

        function initLoadingAnimation() {
            loadingScene = new THREE.Scene();
            loadingCamera = new THREE.PerspectiveCamera(75, loadingAnimationContainer.clientWidth / loadingAnimationContainer.clientHeight, 0.1, 1000);
            loadingRenderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            loadingRenderer.setSize(loadingAnimationContainer.clientWidth, loadingAnimationContainer.clientHeight);
            loadingAnimationContainer.appendChild(loadingRenderer.domElement);

            const loadingGeometry = new THREE.BoxGeometry(1, 1, 1);
            const loadingMaterial = new THREE.MeshBasicMaterial({ color: 0x58a6ff, wireframe: true });
            loadingCube = new THREE.Mesh(loadingGeometry, loadingMaterial);
            loadingScene.add(loadingCube);

            loadingCamera.position.z = 2;

            function animateLoading() {
                requestAnimationFrame(animateLoading);
                loadingCube.rotation.x += 0.01;
                loadingCube.rotation.y += 0.01;
                loadingRenderer.render(loadingScene, loadingCamera);
            }
            animateLoading();

            window.addEventListener('resize', () => {
                loadingRenderer.setSize(loadingAnimationContainer.clientWidth, loadingAnimationContainer.clientHeight);
                loadingCamera.aspect = loadingAnimationContainer.clientWidth / loadingAnimationContainer.clientHeight;
                loadingCamera.updateProjectionMatrix();
            });
        }

        initLoadingAnimation();

        // Hide loading screen once all content (including 3D visualizer) is ready
        window.addEventListener('load', () => {
            setTimeout(() => { 
                loadingScreen.style.opacity = '0';
                appContent.style.opacity = '1';
                setTimeout(() => {
                    loadingScreen.style.display = 'none';
                    resizeVisualizer();
                }, 1000); 
            }, 500); 
        });


        // === THREE.JS AI ORB VISUALIZATION CODE ===
        const visualizerContainer = document.getElementById('visualizer-container');
        let visualizerScene, visualizerCamera, visualizerRenderer, orb;
        let isSpeaking = false; 

        function initVisualizer() {
            visualizerScene = new THREE.Scene();
            visualizerCamera = new THREE.PerspectiveCamera(75, visualizerContainer.clientWidth / visualizerContainer.clientHeight, 0.1, 1000);
            visualizerRenderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            visualizerRenderer.setSize(visualizerContainer.clientWidth, visualizerContainer.clientHeight);
            visualizerContainer.appendChild(visualizerRenderer.domElement);
            
            const ambientLight = new THREE.AmbientLight(0x404040); 
            visualizerScene.add(ambientLight);
            const pointLight = new THREE.PointLight(0xffffff, 1);
            pointLight.position.set(5, 5, 5);
            visualizerScene.add(pointLight);

            const geometry = new THREE.IcosahedronGeometry(1.5, 1);
            const material = new THREE.MeshPhongMaterial({ 
                color: 0x00ffff, 
                emissive: 0x008888, 
                specular: 0xffffff, 
                shininess: 50,
                wireframe: false
            });
            orb = new THREE.Mesh(geometry, material);
            visualizerScene.add(orb);
            visualizerCamera.position.z = 4;

            let pulseFactor = 0;

            function animateVisualizer() {
                requestAnimationFrame(animateVisualizer);
                orb.rotation.x += 0.005;
                orb.rotation.y += 0.008;

                if (isSpeaking) {
                    pulseFactor = Math.sin(Date.now() * 0.005) * 0.15 + 1.1;
                    orb.scale.set(pulseFactor, pulseFactor, pulseFactor);
                    orb.material.emissive.setHex(0xaa00aa); 
                } else {
                    pulseFactor = Math.sin(Date.now() * 0.002) * 0.05 + 1.0;
                    orb.scale.set(pulseFactor, pulseFactor, pulseFactor);
                    orb.material.emissive.setHex(0x008888);
                }
                visualizerRenderer.render(visualizerScene, visualizerCamera);
            }
            animateVisualizer();

            window.addEventListener('resize', resizeVisualizer);
        }

        function resizeVisualizer() {
            const newWidth = visualizerContainer.clientWidth;
            const newHeight = visualizerContainer.clientHeight;
            if(visualizerRenderer){ 
                visualizerRenderer.setSize(newWidth, newHeight);
                visualizerCamera.aspect = newWidth / newHeight;
                visualizerCamera.updateProjectionMatrix();
            }
        }
        
        document.addEventListener('DOMContentLoaded', initVisualizer);


        // === JAVASCRIPT FOR CHAT LOGIC ===

        const recordButton = document.getElementById('record-button');
        const stopButton = document.getElementById('stop-button');
        const micStatus = document.getElementById('mic-status');
        const audioPlayer = document.getElementById('audio-player');
        const messagesDiv = document.getElementById('messages');
        const statusText = document.getElementById('agent-status-text');

        let mediaRecorder;
        let audioChunks = [];
        let stream;

        function addMessage(sender, text, isHtml = false) {
            const messageElement = document.createElement('div');
            messageElement.className = `message-${sender}`;
            const span = document.createElement('span');
            if (isHtml) {
                span.innerHTML = text;
            } else {
                span.textContent = text;
            }
            messageElement.appendChild(span);
            messagesDiv.appendChild(messageElement);
            messagesDiv.scrollTop = messagesDiv.scrollHeight; 
        }

        function updateProfileStatusDisplay(details) {
            document.getElementById('user-name').textContent = details.name === 'N/A' ? 'Missing' : details.name;
            document.getElementById('user-age').textContent = details.age === 0 ? 'Missing' : details.age;
            document.getElementById('user-lang').textContent = details.language;

            if (details.name === 'N/A') {
                statusText.innerHTML = "Agent is collecting your **Name**.";
            } else if (details.age === 0) {
                statusText.innerHTML = "Agent is collecting your **Age**.";
            } else {
                statusText.innerHTML = "<span style='color: green;'>Setup Complete. Agent is in normal chat mode.</span>";
            }
        }
        
        updateProfileStatusDisplay(INITIAL_USER_DETAILS);
        
        // 1. Start Recording
        recordButton.onclick = async () => {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                audioChunks = [];

                mediaRecorder.ondataavailable = event => { audioChunks.push(event.data); };
                mediaRecorder.onstart = () => {
                    isSpeaking = true; 
                    micStatus.textContent = "Microphone Status: üî¥ Recording...";
                    micStatus.className = 'recording';
                    recordButton.disabled = true;
                    stopButton.disabled = false;
                    addMessage('user', 'Recording audio...', true);
                };
                mediaRecorder.onstop = () => {
                    isSpeaking = false; 
                    micStatus.textContent = "Microphone Status: Processing...";
                    micStatus.className = 'processing';
                    stopButton.disabled = true;
                    sendAudio();
                };

                mediaRecorder.start();
            } catch (error) {
                console.error('Error accessing microphone:', error);
                micStatus.textContent = "Microphone Status: ‚ùå Permission Denied";
                micStatus.className = '';
            }
        };

        // 2. Stop Recording
        stopButton.onclick = () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                stream.getTracks().forEach(track => track.stop());
            }
        };

        // 3. Send Audio to Flask Backend (UPDATED TO HANDLE JSON)
        async function sendAudio() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const formData = new FormData();
            formData.append('audio_file', audioBlob, 'user_query.webm');
            
            isSpeaking = true; 

            try {
                const response = await fetch('/chat_audio', {
                    method: 'POST',
                    body: formData
                });

                if (response.ok) {
                    const data = await response.json(); 
                    
                    // Decode Base64 Audio and play
                    const audioContent = 'data:audio/mp3;base64,' + data.audio_base64;
                    
                    audioPlayer.src = audioContent;
                    audioPlayer.play();
                    
                    // Display Agent's Text Response in the log
                    addMessage('agent', data.ai_response_text);
                    
                    isSpeaking = true; 
                    micStatus.textContent = "Microphone Status: üîà Playing AI Response...";
                    micStatus.className = 'playing';
                    
                    audioPlayer.onended = async () => {
                        isSpeaking = false; 
                        micStatus.textContent = "Microphone Status: Idle";
                        micStatus.className = '';
                        recordButton.disabled = false;
                        
                        // Update the profile panel using the details returned in the JSON
                        updateProfileStatusDisplay(data.user_details_updated); 
                    };

                } else {
                    isSpeaking = false;
                    // Handle error response (which should also be JSON)
                    const errorData = await response.json(); 
                    
                    // If the backend returns audio on error, play it
                    if (errorData.audio_base64) {
                        const audioContent = 'data:audio/mp3;base64,' + errorData.audio_base64;
                        audioPlayer.src = audioContent;
                        audioPlayer.play();
                        
                        audioPlayer.onended = () => {
                            isSpeaking = false; 
                            micStatus.textContent = "Microphone Status: Idle";
                            micStatus.className = '';
                            recordButton.disabled = false;
                        };
                        // Use text from the error response (e.g., "I did not catch that.")
                        addMessage('agent', `[Error Audio] ${errorData.ai_response_text || errorData.error}`);
                    } else {
                        // Plain text error fallback
                        micStatus.textContent = `Error: ${errorData.error}`;
                        micStatus.className = '';
                        recordButton.disabled = false;
                        addMessage('agent', `Error: ${errorData.error}`, true);
                    }
                }
            } catch (error) {
                isSpeaking = false;
                console.error('Fetch error:', error);
                micStatus.textContent = `Fatal Error: ${error.message}`;
                micStatus.className = '';
                recordButton.disabled = false;
                addMessage('agent', `Fatal Error: ${error.message}`, true);
            }
        }
    </script>
</body>
</html>